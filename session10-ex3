import random
from collections import Counter


dataset = [
    [2.5, 1.0, 0],
    [1.5, 2.0, 0],
    [3.5, 0.5, 1],
    [3.0, 1.5, 1],
    [2.0, 2.5, 0],
    [3.8, 0.8, 1],
    [1.2, 2.2, 0]
]


# Bootstrap Sampling
def sample_dataset(dataset):
    sample = []
    n = len(dataset)
    for _ in range(n):
        sample.append(random.choice(dataset))
    return sample


# Simple Decision Stump (One-Level Tree)
def build_tree(sample):
    # randomly choose a feature and threshold
    feature_index = random.randint(0, len(sample[0]) - 2)
    threshold = random.choice([row[feature_index] for row in sample])

    left_labels = [row[-1] for row in sample if row[feature_index] < threshold]
    right_labels = [row[-1] for row in sample if row[feature_index] >= threshold]

    left_class = Counter(left_labels).most_common(1)[0][0] if left_labels else 0
    right_class = Counter(right_labels).most_common(1)[0][0] if right_labels else 0

    return feature_index, threshold, left_class, right_class


# Predict Using One Tree
def predict_tree(tree, row):
    feature_index, threshold, left_class, right_class = tree
    if row[feature_index] < threshold:
        return left_class
    else:
        return right_class


# Build Random Forest
def build_forest(dataset, n_trees):
    forest = []
    for _ in range(n_trees):
        sample = sample_dataset(dataset)
        tree = build_tree(sample)
        forest.append(tree)
    return forest


# Predict Using Random Forest (Majority Vote)
def predict_forest(forest, row):
    predictions = [predict_tree(tree, row) for tree in forest]
    return Counter(predictions).most_common(1)[0][0]


# Train Forest
forest = build_forest(dataset, n_trees=5)


# Test Predictions
print("Predictions using Random Forest:")
for row in dataset:
    prediction = predict_forest(forest, row)
    print("Actual:", row[-1], "Predicted:", prediction)
