import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn import tree
import matplotlib.pyplot as plt


# Ecommerce Dataset 
data = {
    "Time_on_Site": [2, 5, 10, 1, 8, 12, 3, 9],
    "Pages_Visited": [3, 8, 15, 2, 12, 18, 4, 14],
    "Ad_Clicks": [0, 1, 2, 0, 2, 3, 0, 1],
    "Add_to_Cart": [0, 1, 3, 0, 2, 4, 0, 2],
    "Purchase": ["No", "Yes", "Yes", "No", "Yes", "Yes", "No", "Yes"]
}

df = pd.DataFrame(data)


# Encode Target Labels
df["Purchase"] = df["Purchase"].map({
    "No": 0,
    "Yes": 1
})


# Features and Target
X = df[["Time_on_Site", "Pages_Visited", "Ad_Clicks", "Add_to_Cart"]]
y = df["Purchase"]


# Train Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)


# Train Decision Tree Model (Without Pruning)
model_full = DecisionTreeClassifier(random_state=42)
model_full.fit(X_train, y_train)

y_pred_full = model_full.predict(X_test)

print("DECISION TREE RESULTS (Before Pruning)")
print("Accuracy:", accuracy_score(y_test, y_pred_full))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_full))


# Apply Pruning to Reduce Overfitting
model_pruned = DecisionTreeClassifier(
    max_depth=3,
    min_samples_leaf=2,
    random_state=42
)

model_pruned.fit(X_train, y_train)

y_pred_pruned = model_pruned.predict(X_test)

print("\nDECISION TREE RESULTS (After Pruning)")
print("Accuracy:", accuracy_score(y_test, y_pred_pruned))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_pruned))
print("Classification Report:\n", classification_report(y_test, y_pred_pruned))


# Visualize Pruned Tree
plt.figure(figsize=(15, 8))
tree.plot_tree(
    model_pruned,
    feature_names=X.columns,
    class_names=["No Purchase", "Purchase"],
    filled=True
)
plt.show()
