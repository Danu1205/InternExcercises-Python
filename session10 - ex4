import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report


# Income Dataset
data = {
    "Age": [22, 35, 29, 45, 50, 23, 40, 33],
    "Education_Level": ["Bachelors", "Masters", "Diploma", "PhD",
                        "Masters", "Bachelors", "PhD", "Diploma"],
    "Hours_Worked": [40, 50, 60, 45, 55, 35, 48, 65],
    "Income_Category": ["LOW", "HIGH", "HIGH", "HIGH",
                        "HIGH", "LOW", "HIGH", "HIGH"]
}

df = pd.DataFrame(data)

# Encode Categorical Column
df["Education_Level"] = df["Education_Level"].map({
    "Diploma": 0,
    "Bachelors": 1,
    "Masters": 2,
    "PhD": 3
})

df["Income_Category"] = df["Income_Category"].map({
    "LOW": 0,
    "HIGH": 1
})


#Features and Target
X = df[["Age", "Education_Level", "Hours_Worked"]]
y = df["Income_Category"]


#Train Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42
)


#Decision Tree Model
dt = DecisionTreeClassifier(max_depth=3, random_state=42)
dt.fit(X_train, y_train)

y_pred_dt = dt.predict(X_test)

print("DECISION TREE RESULTS")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))


# Random Forest Model
rf = RandomForestClassifier(n_estimators=50, random_state=42)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("\nRANDOM FOREST RESULTS")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))


# Feature Importance
print("\nFEATURE IMPORTANCE (Random Forest)")
for feature, importance in zip(X.columns, rf.feature_importances_):
    print(feature, ":", importance)
